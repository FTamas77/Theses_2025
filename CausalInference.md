# ðŸš€ **Machine Learning-Based Causal Inference: Theory & Application**  

## ðŸ“Œ **Introduction**  

Causal inference aims to answer **"What would have happened if..."** questions. Traditional statistical methods like **Ordinary Least Squares (OLS)** regression assume a **single treatment effect** for everyone. However, in reality, different subgroups experience **heterogeneous treatment effects (HTE)**.

This is where **Causal Forests**, implemented in `econml` as `CausalForestDML`, come into play. This document combines **theoretical insights** with a **real-world application** of `CausalForestDML` to analyze power consumption in CNC machines.

---

## ðŸŒ³ **Understanding `CausalForestDML`: A Machine Learning Approach to Causal Inference**  

### ðŸ”Ž **What is `CausalForestDML`?**  

`CausalForestDML` is a **machine learning-based approach** that extends decision trees to estimate **heterogeneous causal effects**. Unlike standard regression models, it:  

âœ… Captures **non-linear relationships** in data.  
âœ… Estimates **different treatment effects** for different subgroups.  
âœ… Works well with **high-dimensional data**.  

### ðŸ— **How Does It Work?**  

1ï¸âƒ£ **Remove Confounding Bias (First-Stage ML Models)**  
   - Estimate **propensity scores** (probability of receiving treatment).  
   - Estimate **expected outcomes** given covariates.  

2ï¸âƒ£ **Estimate Heterogeneous Treatment Effects (HTE) with Causal Forests**  
   - Train a **random forest** to estimate treatment effects.  
   - Split data where treatment effects differ the most.  

---

## ðŸ­ **Case Study: Causal Inference for Power Consumption in CNC Machines**  

### ðŸ“Œ **Problem Statement**  

We analyze the **causal effect of workplace assignment on power consumption** in CNC machines. Traditional OLS regression struggles due to:  

âŒ Assumption of **linear relationships**.  
âŒ Sensitivity to **multicollinearity**.  
âŒ Inability to capture **heterogeneous effects**.  

We compare **OLS Regression** with **CausalForestDML** to show why ML-based causal inference is superior.

### ðŸ“Š **Data Preparation**  

```python
import pandas as pd
from sklearn.preprocessing import LabelEncoder

# Load dataset
df = pd.read_csv("stainless_steel_energy.csv", sep=";", encoding="utf-8", on_bad_lines="skip")
df.rename(columns={"value": "power_consumption"}, inplace=True)

# Handle numeric values (European decimal format)
for col in numeric_columns:
    df[col] = pd.to_numeric(df[col].astype(str).str.replace(",", "."), errors='coerce')

# Fill missing values
df.fillna(df.median(numeric_only=True), inplace=True)

# Encode categorical treatment variable
df["workplace_id"] = LabelEncoder().fit_transform(df["workplace_id"])
```

### ðŸ“Œ **Causal Graph (DAG) Using DoWhy**

Before applying CausalForestDML, we visualize causal relationships.

```python
from dowhy import CausalModel

model = CausalModel(
    data=df,
    treatment="workplace_id",
    outcome="power_consumption",
    common_causes=["input_weight", "weight"]
)
model.view_model()  # Generate DAG
```

### ðŸ“Š **Expected DAG Structure**

```
workplace_id  â†’  power_consumption
    â†‘              
    |  
 input_weight, weight  (Confounders)
```

### ðŸŒ² **Applying CausalForestDML for Causal Inference**

```python
from econml.dml import CausalForestDML
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
import numpy as np

dml_estimator = CausalForestDML(
    model_t=RandomForestClassifier(n_estimators=100, random_state=42),
    model_y=RandomForestRegressor(n_estimators=100, random_state=42),
    discrete_treatment=True
)
dml_estimator.fit(Y, T, X=X)
treatment_effects = dml_estimator.effect(X)
mean_effect = np.mean(treatment_effects)
```

ðŸ“Œ **Key Takeaway:** Unlike OLS, CausalForestDML estimates how treatment effects vary across different workplaces.

### ðŸ”¬ **Validation: Placebo Test**

To confirm the validity of causal estimates, we shuffle treatment labels and recompute effects.

```python
np.random.shuffle(T)  # Randomize treatment labels
dml_estimator.fit(Y, T, X=X)  # Refit model
placebo_effects = dml_estimator.effect(X)
placebo_mean = np.mean(placebo_effects)
```

### ðŸ“Š **Results Comparison**

| Method | Estimated Effect |
| ------ | --------------- |
| âœ… True Treatment Effect (CausalForestDML) | -7.0973 |
| âŒ Placebo (Randomized Treatment) | 38.1215 |

### ðŸ” **Interpretation**

- The true effect (-7.1) is meaningful.
- The placebo test produces a randomized effect (+38.1), confirming model validity.

---

## ðŸ“Œ **Comparing CausalForestDML with OLS Regression**

### âŒ **Why OLS Fails**

OLS regression has fundamental limitations:
- âŒ Assumes constant treatment effects.
- âŒ Sensitive to multicollinearity.
- âŒ Produces unrealistic effect sizes in complex settings.

```python
import statsmodels.api as sm

X_ols = np.column_stack((np.ones(len(X)), X, pd.get_dummies(df["workplace_id"])))
ols_model = sm.OLS(Y, X_ols).fit()
```

### ðŸ“Š **OLS Regression Results**

| Metric | OLS Regression |
| ------ | --------------- |
| R-Squared (Model Fit) | 0.518 (51.8%) |
| Treatment Effect Estimates | Unrealistically Large (-6.24e+11) |
| p-values (Significance Test) | 0.983 (Not Significant) |
| Multicollinearity Check (Condition Number) | 5.05e+16 (Severe Issues) |

âŒ OLS fails completely!

- High p-values (0.98) â†’ No significant relationship.
- Extremely large coefficients â†’ Unrealistic results.
- Multicollinearity issues â†’ The model is unreliable.

âœ… CausalForestDML is the better approach!

### ðŸŽ¯ **Key Takeaways**

| Feature | CausalForestDML (âœ… Better) | OLS Regression (âŒ Fails) |
| ------- | --------------------------- | ------------------------ |
| Handles Non-Linearity | âœ… Yes (Flexible) | âŒ No (Linear Only) |
| Handles Multicollinearity | âœ… Yes | âŒ No (Severe Issues) |
| Heterogeneous Effects | âœ… Yes (Varies by Workplace) | âŒ No (Single Estimate) |
| Statistical Validity | âœ… Strong (Valid Placebo Test) | âŒ Weak (p > 0.98, Large Errors) |

âœ… **Conclusion:**

- OLS fails due to multicollinearity & restrictive assumptions.
- CausalForestDML correctly estimates heterogeneous causal effects.
- ML-based causal inference is superior for real-world industrial data! ðŸš€

### ðŸ“Œ **Recommendations for Energy Efficiency**

- âœ… Investigate workplace efficiency differences.
- âœ… Analyze machine maintenance schedules.
- âœ… Train operators for energy efficiency.
- âœ… Collect more data (e.g., temperature settings).

ðŸš€ **ML-Based Causal Inference is the Future!**
- âœ… More accurate, interpretable, and actionable insights than traditional regression!

